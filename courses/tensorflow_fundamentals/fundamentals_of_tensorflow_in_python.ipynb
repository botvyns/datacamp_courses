{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Fundamentral of TensorFlow in Python**\n",
        "1. Intro\n",
        "2. Linear Models\n",
        "3. Neural Networks\n",
        "4. High Level APIs"
      ],
      "metadata": {
        "id": "QvN-ew5dIHvR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Intro**"
      ],
      "metadata": {
        "id": "yFIhss7bIWgc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is a tensor?\n",
        "- collection of numbers with a specific shape\n",
        "\n",
        "What is a constant?\n",
        "- a simplest category of a tensor\n",
        "\n",
        "Unlike a constant variable can be modified + variable is useful when we want to train a model by updating its parameters"
      ],
      "metadata": {
        "id": "r8ApeOstwEyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "VAgIhskHxJon"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Constants and variables**"
      ],
      "metadata": {
        "id": "dlBoCbly6Of_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "credit_numpy = np.array([2,34,5])"
      ],
      "metadata": {
        "id": "9tEfO4ef4aWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the credit_numpy array into a tensorflow constant\n",
        "credit_constant = tf.constant(credit_numpy)\n",
        "\n",
        "# Print constant datatype\n",
        "print('\\n The datatype is:', credit_constant.dtype)\n",
        "\n",
        "# Print constant shape\n",
        "print('\\n The shape is:', credit_constant.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6M7tHkpvr0p",
        "outputId": "a5b31066-0e61-43e4-e230-1f48b0f6a136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " The datatype is: <dtype: 'int64'>\n",
            "\n",
            " The shape is: (3,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the 1-dimensional variable A1\n",
        "A1 = tf.Variable([1, 2, 3, 4])\n",
        "\n",
        "# Print the variable A1\n",
        "print('\\n A1: ', A1)\n",
        "\n",
        "# Convert A1 to a numpy array and assign it to B1\n",
        "B1 = A1.numpy()\n",
        "\n",
        "# Print B1\n",
        "print('\\n B1: ', B1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMt1s2zFxQnS",
        "outputId": "09f8547a-efad-4527-ea3f-6184ea3b9442"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " A1:  <tf.Variable 'Variable:0' shape=(4,) dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)>\n",
            "\n",
            " B1:  [1 2 3 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basic operations**"
      ],
      "metadata": {
        "id": "RN-g61Zo6UWc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is element-wise multiplication?\n",
        "\n",
        "- tensors of identical shapes, multiply elements in correspondimg positions"
      ],
      "metadata": {
        "id": "2JkB4nkozG2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define tensors A1 and A23 as constants\n",
        "A1 = tf.constant([1, 2, 3, 4])\n",
        "A23 = tf.constant([[1, 2, 3], [1, 6, 4]])\n",
        "\n",
        "# Define B1 and B23 to have the correct shape\n",
        "B1 = tf.ones_like([1, 2, 3, 4])\n",
        "B23 = tf.ones_like([[1, 2, 3], [1, 6, 4]])\n",
        "\n",
        "# Perform element-wise multiplication\n",
        "C1 = tf.multiply(A1, B1)\n",
        "C23 = tf.multiply(A23, B23)\n",
        "\n",
        "# Print the tensors C1 and C23\n",
        "print('\\n C1: {}'.format(C1.numpy()))\n",
        "print('\\n C23: {}'.format(C23.numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isGmrBYByIRx",
        "outputId": "0411e1d6-3237-41fa-f7e9-58be77c67222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " C1: [1 2 3 4]\n",
            "\n",
            " C23: [[1 2 3]\n",
            " [1 6 4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features, params, and bill as tf.constants\n",
        "features = tf.constant([[2, 24], [2, 26], [2, 57], [1, 37]])\n",
        "params = tf.constant([[1000], [150]])\n",
        "bill = tf.constant([[3913], [2682], [8617], [64400]])\n",
        "\n",
        "# Compute billpred using features and params\n",
        "billpred = tf.matmul(features, params)\n",
        "\n",
        "# Compute and print the error\n",
        "error = bill - billpred\n",
        "print(error.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMZpipTY0gjM",
        "outputId": "08cd7612-2cbc-42cb-f543-cbf4d9faeb50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1687]\n",
            " [-3218]\n",
            " [-1933]\n",
            " [57850]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.constant([[1,1,1], [1,1,1]])\n",
        "\n",
        "print(tf.reduce_sum(x).numpy()) # sum all the elements\n",
        "print(tf.reduce_sum(x, 0).numpy()) # reduce along the first dimension\n",
        "print(tf.reduce_sum(x, 1).numpy()) # reduce along the second dimesion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpEcbZtH8-sJ",
        "outputId": "02aab620-718e-4500-c023-0ffb0d8ffc00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "[2 2 2]\n",
            "[3 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Advanced operations**"
      ],
      "metadata": {
        "id": "hQG-IihU8zHx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Finding the optimum*\n",
        " - minimum: lowest value of the lost function\n",
        " - maximum: highest value of a lost function\n",
        " - at this poin gradient (slope at a given point) = 0\n",
        " - change > 0 -> minimum\n",
        " -  change < 0 -> maximum"
      ],
      "metadata": {
        "id": "wsATkRir-Oo3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gray_tensor = tf.constant(0, shape=(28, 28))\n",
        "color_tensor = tf.constant(0, shape=(28, 28, 3))\n",
        "\n",
        "# Reshape the grayscale image tensor into a vector\n",
        "gray_vector = tf.reshape(gray_tensor, (784, 1))\n",
        "\n",
        "# tf.Reshape the color image tensor into a vector\n",
        "color_vector = tf.reshape(color_tensor, (2352, 1))"
      ],
      "metadata": {
        "id": "GLcUW9Ou1QZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*loss function*  = x * x\n",
        "To minimize the loss function:\n",
        "- positive slope? decrease x\n",
        "- negative slope? increase x"
      ],
      "metadata": {
        "id": "YNXnXdLyALAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradient(x0):\n",
        "  \t# Define x as a variable with an initial value of x0\n",
        "\tx = tf.Variable(x0)\n",
        "\twith tf.GradientTape() as tape:\n",
        "\t\ttape.watch(x)\n",
        "        # Define y using the multiply operation\n",
        "\t\ty = tf.multiply(x, x)\n",
        "    # Return the gradient of y with respect to x\n",
        "\treturn tape.gradient(y,x).numpy()\n",
        "\n",
        "# Compute and print gradients at x = -1, 1, and 0\n",
        "print(compute_gradient(-1.0))\n",
        "print(compute_gradient(1.0))\n",
        "print(compute_gradient(0.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3juQ1lC5lz0",
        "outputId": "7ade4c48-33e3-4cda-c0ed-b9755ea9f67e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-2.0\n",
            "2.0\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the slope is positive at x = 1, which means that we can lower the loss by reducing x. The slope is negative at x = -1, which means that we can lower the loss by increasing x. The slope at x = 0 is 0, which means that we cannot lower the loss by either increasing or decreasing x. This is because the loss is minimized at x = 0."
      ],
      "metadata": {
        "id": "UCt0xsvK6WKB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Linear Models**"
      ],
      "metadata": {
        "id": "yXEbfz5FIjwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.constant([[ 1.,  0., -1.]]) # 1x3 tensor\n",
        "\n",
        "letter = tf.constant([[1., 0., 1.],\n",
        "       [1., 1., 0.],\n",
        "       [1., 0., 1.]]) # 3x3 tensor\n",
        "\n",
        "# Reshape model from a 1x3 to a 3x1 tensor\n",
        "model = tf.reshape(model, (3,1))\n",
        "\n",
        "# Multiply letter by model\n",
        "output = tf.matmul(letter, model)\n",
        "\n",
        "# Sum over output and print prediction using the numpy method\n",
        "prediction = tf.reduce_sum(output)\n",
        "print(prediction.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "em-Cl4wM6PhX",
        "outputId": "fb5f6fa8-f087-4643-b35c-7481de01a5e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model found that prediction=1.0 and correctly classified the letter as a K"
      ],
      "metadata": {
        "id": "E5D8QoLOA_Ji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Input data**"
      ],
      "metadata": {
        "id": "ivl9SGUsBGJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign the path to a string variable named data_path\n",
        "data_path = 'kc_house_data.csv'\n",
        "\n",
        "# Load the dataset as a dataframe named housing\n",
        "housing = pd.read_csv(data_path)\n",
        "\n",
        "# Print the price column of housing\n",
        "print(housing.price)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTrb-CwjDu2u",
        "outputId": "baa8c1a1-02db-4f8d-e1ac-e51b12ef698c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        221900.0\n",
            "1        538000.0\n",
            "2        180000.0\n",
            "3        604000.0\n",
            "4        510000.0\n",
            "           ...   \n",
            "21608    360000.0\n",
            "21609    400000.0\n",
            "21610    402101.0\n",
            "21611    400000.0\n",
            "21612    325000.0\n",
            "Name: price, Length: 21613, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a numpy array to define price as a 32-bit float\n",
        "price = np.array(housing['price'], np.float32)\n",
        "\n",
        "# Define waterfront as a Boolean using cast\n",
        "waterfront = tf.cast(housing['waterfront'], tf.bool)\n",
        "\n",
        "# Print price and waterfront\n",
        "print(price) # numpy array\n",
        "print(waterfront) # tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0W_GAYTELA3",
        "outputId": "a56f7b19-30d6-472c-984b-15e29f86dda5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[221900. 538000. 180000. ... 402101. 400000. 325000.]\n",
            "tf.Tensor([False False False ... False False False], shape=(21613,), dtype=bool)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss functions**"
      ],
      "metadata": {
        "id": "q143l3oRChLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "price = np.array([402101, 400000, 325000])\n",
        "predictions = np.array([369047.72405433, 162293.96762846, 148248.92465109])\n",
        "\n",
        "# Compute the mean absolute error (mae)\n",
        "loss = tf.keras.losses.mse(price, predictions)\n",
        "\n",
        "# Print the mean absolute error (mae)\n",
        "print(loss.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxpPrm5REx8W",
        "outputId": "85d71a6a-6348-4f8c-c5dc-9d50a3218e27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29612539837.852097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the mean absolute error (mae)\n",
        "loss = tf.keras.losses.mae(price, predictions)\n",
        "\n",
        "# Print the mean absolute error (mae)\n",
        "print(loss.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7N0Ww6npVbkg",
        "outputId": "00afe9c0-ab9e-4be7-d3ea-12341d08bfc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "149170.12788870666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss functions vary in result as they penalize the deviations in different way. MSE is more harsh with large deviations, so its is significantly higher than MAE"
      ],
      "metadata": {
        "id": "2rqKzTMXYHBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a variable named scalar\n",
        "scalar = tf.Variable(1.0, tf.float32)\n",
        "features = tf.constant([1,2,3,4,5], tf.float32)\n",
        "targets = tf.constant([2,4,6,8,10], tf.float32)\n",
        "\n",
        "# Define the model\n",
        "def model(scalar, features = features):\n",
        "  \treturn scalar * features\n",
        "\n",
        "# Define a loss function\n",
        "def loss_function(scalar, features = features, targets = targets):\n",
        "\t# Compute the predicted values\n",
        "\tpredictions = model(scalar, features)\n",
        "\n",
        "\t# Return the mean absolute error loss\n",
        "\treturn tf.keras.losses.mae(targets, predictions)\n",
        "\n",
        "# Evaluate the loss function and print the loss\n",
        "print(loss_function(scalar).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNwMySK8WgBj",
        "outputId": "0ea04060-e97c-4355-9dfd-eba40035db05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear regression**"
      ],
      "metadata": {
        "id": "N8w2ef97DYmi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A univariate linear regression identifies the relationship between a single feature and the target tensor."
      ],
      "metadata": {
        "id": "QfD1hoqIYYWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "size_log = tf.constant([8.639411 , 8.887652 , 9.2103405, 7.20786  , 7.7782116,\n",
        "       6.9810057], tf.float32)\n",
        "\n",
        "price_log = tf.constant([12.309982 , 13.195614 , 12.100712, 12.904459 , 12.8992195,\n",
        "       12.691581], tf.float32)\n",
        "\n",
        "# Define a linear regression model\n",
        "def linear_regression(intercept, slope, features = size_log):\n",
        "\treturn intercept + slope*features\n",
        "\n",
        "# Set loss_function() to take the variables as arguments\n",
        "def loss_function(intercept, slope, features = size_log, targets = price_log):\n",
        "\t# Set the predicted values\n",
        "\tpredictions = linear_regression(intercept, slope, features)\n",
        "\n",
        "    # Return the mean squared error loss\n",
        "\treturn tf.keras.losses.mse(targets, predictions)\n",
        "\n",
        "# Compute the loss for different slope and intercept values\n",
        "print(loss_function(0.1, 0.1))\n",
        "print(loss_function(0.1, 0.5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Othytm8VW1Wp",
        "outputId": "e918350b-dbbe-4a54-8582-03356b8a7fae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(138.74718, shape=(), dtype=float32)\n",
            "tf.Tensor(73.112236, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_results(intercept, slope):\n",
        "\tsize_range = np.linspace(6,14,100)\n",
        "\tprice_pred = [intercept+slope*s for s in size_range]\n",
        "\tplt.scatter(size_log, price_log, color = 'black')\n",
        "\tplt.plot(size_range, price_pred, linewidth=3.0, color='red')\n",
        "\tplt.xlabel('log(size)')\n",
        "\tplt.ylabel('log(price)')\n",
        "\tplt.title('Scatterplot of data and fitted regression line')\n",
        "\tplt.show()"
      ],
      "metadata": {
        "id": "auAG_rADhWLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an Adam optimizer\n",
        "opt = tf.keras.optimizers.Adam(0.5)\n",
        "intercept = tf.Variable(0.0, tf.int32)\n",
        "slope = tf.Variable(0.0, tf.int32)\n",
        "\n",
        "for j in range(100):\n",
        "\t# Apply minimize, pass the loss function, and supply the variables\n",
        "\topt.minimize(lambda: loss_function(intercept, slope), var_list=[intercept, slope])\n",
        "\n",
        "\t# Print every 10th value of the loss\n",
        "\tif j % 10 == 0:\n",
        "\t\tprint(loss_function(intercept, slope).numpy())\n",
        "\n",
        "plot_results(intercept, slope)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "nx4N31aSZB1N",
        "outputId": "7dae86b8-a51b-45ed-d989-836f6d217710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "66.45283\n",
            "2.4379816\n",
            "1.8019257\n",
            "2.050548\n",
            "2.30178\n",
            "2.1166975\n",
            "1.72618\n",
            "1.57312\n",
            "1.5390075\n",
            "1.466803\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we printed loss_function(intercept, slope) every 10th execution for 100 executions. Each time, the loss got closer to the minimum as the optimizer moved the slope and intercept parameters closer to their optimal values."
      ],
      "metadata": {
        "id": "3hH-YVJadMrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGxi_rnxEjA3",
        "outputId": "fbcfa54d-bd4a-4769-f601-805f36626606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'date', 'price', 'bedrooms', 'bathrooms', 'sqft_living',\n",
              "       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
              "       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
              "       'lat', 'long', 'sqft_living15', 'sqft_lot15'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Initialize parameters as trainable variables\n",
        "params = tf.Variable([0.1, 0.05, 0.02], dtype=tf.float32, trainable=True)\n",
        "\n",
        "# Input features\n",
        "size_log = np.log(housing['sqft_living'])\n",
        "bedrooms = np.array(housing['bedrooms'])\n",
        "\n",
        "# Target variable\n",
        "price_log = np.log(housing['price'])\n",
        "\n",
        "# Define the linear regression model\n",
        "def linear_regression(params, feature1, feature2):\n",
        "    return params[0] + feature1 * params[1] + feature2 * params[2]\n",
        "\n",
        "# Define the loss function\n",
        "def loss_function(params, targets, feature1, feature2):\n",
        "    # Set the predicted values\n",
        "    predictions = linear_regression(params, feature1, feature2)\n",
        "\n",
        "    # Use the mean absolute error loss\n",
        "    return tf.keras.losses.mae(targets, predictions)\n",
        "\n",
        "# Define the optimization operation\n",
        "opt = tf.keras.optimizers.Adam()\n",
        "\n",
        "# Perform minimization and print trainable variables\n",
        "for j in range(10):\n",
        "    opt.minimize(lambda: loss_function(params, price_log, size_log, bedrooms), var_list=[params])\n",
        "    loss_value = loss_function(params, price_log, size_log, bedrooms).numpy()\n",
        "    print(f\"Iteration {j + 1}, Loss: {loss_value}\")\n",
        "    print(f\"Updated Parameters: {params.numpy()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4K32c0LeRET",
        "outputId": "a836597d-9b9f-4491-838d-37a225e54c25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, Loss: 12.498513221740723\n",
            "Updated Parameters: [0.10099999 0.05       0.02099999]\n",
            "Iteration 2, Loss: 12.494141578674316\n",
            "Updated Parameters: [0.10199998 0.05       0.02199998]\n",
            "Iteration 3, Loss: 12.48976993560791\n",
            "Updated Parameters: [0.10299997 0.05       0.02299998]\n",
            "Iteration 4, Loss: 12.485401153564453\n",
            "Updated Parameters: [0.10399996 0.05       0.02399997]\n",
            "Iteration 5, Loss: 12.48102855682373\n",
            "Updated Parameters: [0.10499994 0.05       0.02499996]\n",
            "Iteration 6, Loss: 12.47665786743164\n",
            "Updated Parameters: [0.10599994 0.05       0.02599995]\n",
            "Iteration 7, Loss: 12.472288131713867\n",
            "Updated Parameters: [0.10699993 0.05       0.02699994]\n",
            "Iteration 8, Loss: 12.467917442321777\n",
            "Updated Parameters: [0.10799993 0.05       0.02799994]\n",
            "Iteration 9, Loss: 12.463545799255371\n",
            "Updated Parameters: [0.10899992 0.05       0.02899993]\n",
            "Iteration 10, Loss: 12.459177017211914\n",
            "Updated Parameters: [0.10999992 0.05       0.02999992]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the intercept and slope\n",
        "intercept = tf.Variable(10.0, tf.float32)\n",
        "slope = tf.Variable(0.5, tf.float32)\n",
        "\n",
        "# Define the model\n",
        "def linear_regression(intercept, slope, features):\n",
        "\t# Define the predicted values\n",
        "\treturn intercept + slope*features\n",
        "\n",
        "# Define the loss function\n",
        "def loss_function(intercept, slope, targets, features):\n",
        "\t# Define the predicted values\n",
        "\tpredictions = linear_regression(intercept, slope, features)\n",
        "\n",
        " \t# Define the MSE loss\n",
        "\treturn tf.keras.losses.mse(targets, predictions)"
      ],
      "metadata": {
        "id": "XA3iiiolfvOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Epoch* = passing though an entire dataset\n",
        "\n",
        "*Batch* = part of the dataset\n",
        "\n",
        "*iteration* = hpw many time you shoul feed batch to use all dataset"
      ],
      "metadata": {
        "id": "K4I9wWVnGZLA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Full sample* vs *batch training*\n",
        "\n",
        "\n",
        "1.   one update per epoch VS multiple updates per epoch\n",
        "2.   dataset modification VS no modification\n",
        "3. limited memory VS no limit on data size\n",
        "\n"
      ],
      "metadata": {
        "id": "tQ0djsMjG6qf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Adam optimizer\n",
        "opt = tf.keras.optimizers.Adam()\n",
        "\n",
        "# Load data in batches\n",
        "for batch in pd.read_csv('kc_house_data.csv', chunksize=100):\n",
        "\tsize_batch = np.array(batch['sqft_lot'], np.float32)\n",
        "\n",
        "\t# Extract the price values for the current batch\n",
        "\tprice_batch = np.array(batch['price'], np.float32)\n",
        "\n",
        "\t# Complete the loss, fill in the variable list, and minimize\n",
        "\topt.minimize(lambda: loss_function(intercept, slope, price_batch, size_batch), var_list=[intercept, slope])\n",
        "\n",
        "# Print trained parameters\n",
        "print(intercept.numpy(), slope.numpy()) # updates slope and intercept with every batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-E5GdpnkdTT",
        "outputId": "2034d0b3-af3c-4fbc-f2b9-2caf11b6ec7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.217887 0.7015986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Neural Networks**"
      ],
      "metadata": {
        "id": "9_lVSIT7H72W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two ways to define a dense layer in TensorFlow?\n",
        "- low-level, linear algebraic operations\n",
        "- hight-level keras operations"
      ],
      "metadata": {
        "id": "XKhZrY71M8Ey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize bias1\n",
        "bias1 = tf.Variable(1.0)\n",
        "borrower_features = tf.constant([[ 2.,  2., 43.]])\n",
        "\n",
        "# Initialize weights1 as 3x2 variable of ones\n",
        "weights1 = tf.Variable(tf.ones((3,2)))\n",
        "\n",
        "# Perform matrix multiplication of borrower_features and weights1\n",
        "product1 = tf.matmul( borrower_features, weights1)\n",
        "\n",
        "# Apply sigmoid activation function to product1 + bias1\n",
        "dense1 = tf.keras.activations.sigmoid(product1 + bias1)\n",
        "\n",
        "# Print shape of dense1\n",
        "print(\"\\n dense1's output shape: {}\".format(dense1.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDwlS04slHS7",
        "outputId": "1c9bae26-3750-496f-b22c-a8fefca7555b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " dense1's output shape: (1, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# weights1"
      ],
      "metadata": {
        "id": "BTsfKQgnNilx"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From previous step\n",
        "bias1 = tf.Variable(1.0)\n",
        "weights1 = tf.Variable(tf.ones((3, 2)))\n",
        "product1 = tf.matmul(borrower_features, weights1)\n",
        "dense1 = tf.keras.activations.sigmoid(product1 + bias1)\n",
        "\n",
        "# Initialize bias2 and weights2\n",
        "bias2 = tf.Variable(1.0)\n",
        "weights2 = tf.Variable(tf.ones((2, 1)))\n",
        "\n",
        "# Perform matrix multiplication of dense1 and weights2\n",
        "product2 = tf.matmul(dense1, weights2)\n",
        "\n",
        "# Apply activation to product2 + bias2 and print the prediction\n",
        "prediction = tf.keras.activations.sigmoid(product2 + bias2)\n",
        "print('\\n prediction: {}'.format(prediction.numpy()[0,0]))\n",
        "print('\\n actual: 1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrLtFwCtpuUj",
        "outputId": "8fcdc9bf-9f7a-48d3-b902-52a04b6069df"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " prediction: 0.9525741338729858\n",
            "\n",
            " actual: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Our model produces predicted values in the interval between 0 and 1. For the example we considered, the actual value was 1 and the predicted value was a probability between 0 and 1. This, of course, is not meaningful, since we have not yet trained our model's parameters."
      ],
      "metadata": {
        "id": "eUPsKan_qZaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define borrower_features tensor\n",
        "borrower_features = tf.constant([[3., 3., 23.],\n",
        "                                 [2., 1., 24.],\n",
        "                                 [1., 1., 49.],\n",
        "                                 [1., 1., 49.],\n",
        "                                 [2., 1., 29.]], dtype=tf.float32)\n",
        "\n",
        "# Define weights1 tensor\n",
        "weights1 = tf.constant([[-0.6, 0.6],\n",
        "                        [0.8, -0.3],\n",
        "                        [-0.09, -0.08]], dtype=tf.float32)\n",
        "\n",
        "# Define bias1 tensor\n",
        "bias1 = tf.constant([0.1], dtype=tf.float32)"
      ],
      "metadata": {
        "id": "760nPlETrZLC"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the product of borrower_features and weights1\n",
        "products1 = tf.matmul(borrower_features, weights1)\n",
        "\n",
        "# Apply a sigmoid activation function to products1 + bias1\n",
        "dense1 = tf.keras.activations.sigmoid(products1 + bias1)\n",
        "\n",
        "# Print the shapes of borrower_features, weights1, bias1, and dense1\n",
        "print('\\n shape of borrower_features: ', borrower_features.shape)\n",
        "print('\\n shape of weights1: ', weights1.shape)\n",
        "print('\\n shape of bias1: ', bias1.shape)\n",
        "print('\\n shape of dense1: ', dense1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2AJsC1dqOix",
        "outputId": "7fd96dd4-304f-41a9-f546-5e4f81f0a84b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " shape of borrower_features:  (5, 3)\n",
            "\n",
            " shape of weights1:  (3, 2)\n",
            "\n",
            " shape of bias1:  (1,)\n",
            "\n",
            " shape of dense1:  (5, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "our input data, borrower_features, is 5x3 because it consists of 5 examples for 3 features. The shape of weights1 is 3x2, as it was in the previous exercise, since it does not depend on the number of examples. Additionally, bias1 is a scalar. Finally, dense1 is 5x2, which means that we can multiply it by the following set  weights2 which we defined to be 2x1 in the previous exercise."
      ],
      "metadata": {
        "id": "r7hRDK85rf1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "borrower_features = tf.constant([[6.96469188e-01, 2.86139339e-01, 2.26851448e-01, 5.51314771e-01,\n",
        "        7.19468951e-01, 4.23106462e-01, 9.80764210e-01, 6.84829712e-01,\n",
        "        4.80931908e-01, 3.92117530e-01],\n",
        "       [3.43178004e-01, 7.29049683e-01, 4.38572258e-01, 5.96778952e-02,\n",
        "        3.98044258e-01, 7.37995386e-01, 1.82491735e-01, 1.75451756e-01,\n",
        "        5.31551361e-01, 5.31827569e-01],\n",
        "       [6.34400964e-01, 8.49431813e-01, 7.24455297e-01, 6.11023486e-01,\n",
        "        7.22443402e-01, 3.22958916e-01, 3.61788660e-01, 2.28263229e-01,\n",
        "        2.93714046e-01, 6.30976140e-01],\n",
        "       [9.21049416e-02, 4.33701187e-01, 4.30862755e-01, 4.93685097e-01,\n",
        "        4.25830305e-01, 3.12261224e-01, 4.26351309e-01, 8.93389165e-01,\n",
        "        9.44160044e-01, 5.01836658e-01],\n",
        "       [6.23952925e-01, 1.15618393e-01, 3.17285478e-01, 4.14826214e-01,\n",
        "        8.66309166e-01, 2.50455379e-01, 4.83034253e-01, 9.85559762e-01,\n",
        "        5.19485116e-01, 6.12894535e-01],\n",
        "       [1.20628662e-01, 8.26340795e-01, 6.03060126e-01, 5.45068026e-01,\n",
        "        3.42763841e-01, 3.04120779e-01, 4.17022198e-01, 6.81300759e-01,\n",
        "        8.75456870e-01, 5.10422349e-01],\n",
        "       [6.69313788e-01, 5.85936546e-01, 6.24903500e-01, 6.74689054e-01,\n",
        "        8.42342436e-01, 8.31949860e-02, 7.63682842e-01, 2.43666381e-01,\n",
        "        1.94222957e-01, 5.72456956e-01],\n",
        "       [9.57125202e-02, 8.85326803e-01, 6.27248943e-01, 7.23416328e-01,\n",
        "        1.61292069e-02, 5.94431877e-01, 5.56785166e-01, 1.58959642e-01,\n",
        "        1.53070509e-01, 6.95529521e-01],\n",
        "       [3.18766415e-01, 6.91970289e-01, 5.54383278e-01, 3.88950586e-01,\n",
        "        9.25132513e-01, 8.41669977e-01, 3.57397556e-01, 4.35914621e-02,\n",
        "        3.04768085e-01, 3.98185670e-01],\n",
        "       [7.04958856e-01, 9.95358467e-01, 3.55914861e-01, 7.62547791e-01,\n",
        "        5.93176901e-01, 6.91701770e-01, 1.51127458e-01, 3.98876280e-01,\n",
        "        2.40855902e-01, 3.43456000e-01],\n",
        "       [5.13128161e-01, 6.66624546e-01, 1.05908483e-01, 1.30894944e-01,\n",
        "        3.21980596e-01, 6.61564350e-01, 8.46506238e-01, 5.53257346e-01,\n",
        "        8.54452491e-01, 3.84837806e-01],\n",
        "       [3.16787899e-01, 3.54264677e-01, 1.71081826e-01, 8.29112649e-01,\n",
        "        3.38670850e-01, 5.52370071e-01, 5.78551471e-01, 5.21533072e-01,\n",
        "        2.68806447e-03, 9.88345444e-01],\n",
        "       [9.05341566e-01, 2.07635865e-01, 2.92489409e-01, 5.20010173e-01,\n",
        "        9.01911378e-01, 9.83630896e-01, 2.57542074e-01, 5.64359069e-01,\n",
        "        8.06968689e-01, 3.94370049e-01],\n",
        "       [7.31073022e-01, 1.61069021e-01, 6.00698590e-01, 8.65864456e-01,\n",
        "        9.83521581e-01, 7.93657899e-02, 4.28347290e-01, 2.04542860e-01,\n",
        "        4.50636476e-01, 5.47763586e-01],\n",
        "       [9.33267102e-02, 2.96860784e-01, 9.27584231e-01, 5.69003761e-01,\n",
        "        4.57412004e-01, 7.53525972e-01, 7.41862178e-01, 4.85790335e-02,\n",
        "        7.08697379e-01, 8.39243352e-01],\n",
        "       [1.65937886e-01, 7.80997932e-01, 2.86536604e-01, 3.06469738e-01,\n",
        "        6.65261447e-01, 1.11392170e-01, 6.64872468e-01, 8.87856781e-01,\n",
        "        6.96311295e-01, 4.40327883e-01],\n",
        "       [4.38214391e-01, 7.65096068e-01, 5.65641999e-01, 8.49041641e-02,\n",
        "        5.82671106e-01, 8.14843714e-01, 3.37066382e-01, 9.27576602e-01,\n",
        "        7.50716984e-01, 5.74063838e-01],\n",
        "       [7.51644015e-01, 7.91489631e-02, 8.59389067e-01, 8.21504116e-01,\n",
        "        9.09871638e-01, 1.28631204e-01, 8.17800835e-02, 1.38415575e-01,\n",
        "        3.99378717e-01, 4.24306870e-01],\n",
        "       [5.62218368e-01, 1.22243546e-01, 2.01399505e-01, 8.11644375e-01,\n",
        "        4.67987567e-01, 8.07938218e-01, 7.42637832e-03, 5.51592708e-01,\n",
        "        9.31932151e-01, 5.82175434e-01],\n",
        "       [2.06095725e-01, 7.17757583e-01, 3.78985852e-01, 6.68383956e-01,\n",
        "        2.93197222e-02, 6.35900378e-01, 3.21979336e-02, 7.44780660e-01,\n",
        "        4.72912997e-01, 1.21754356e-01],\n",
        "       [5.42635918e-01, 6.67744428e-02, 6.53364897e-01, 9.96086299e-01,\n",
        "        7.69397318e-01, 5.73774099e-01, 1.02635257e-01, 6.99834049e-01,\n",
        "        6.61167860e-01, 4.90971319e-02],\n",
        "       [7.92299330e-01, 5.18716574e-01, 4.25867707e-01, 7.88187146e-01,\n",
        "        4.11569238e-01, 4.81026262e-01, 1.81628838e-01, 3.21318895e-01,\n",
        "        8.45533013e-01, 1.86903745e-01],\n",
        "       [4.17291075e-01, 9.89034534e-01, 2.36599818e-01, 9.16832328e-01,\n",
        "        9.18397486e-01, 9.12963450e-02, 4.63652730e-01, 5.02216339e-01,\n",
        "        3.13668936e-01, 4.73395362e-02],\n",
        "       [2.41685644e-01, 9.55296382e-02, 2.38249913e-01, 8.07791114e-01,\n",
        "        8.94978285e-01, 4.32228930e-02, 3.01946849e-01, 9.80582178e-01,\n",
        "        5.39504826e-01, 6.26309335e-01],\n",
        "       [5.54540846e-03, 4.84909445e-01, 9.88328516e-01, 3.75185519e-01,\n",
        "        9.70381573e-02, 4.61908758e-01, 9.63004470e-01, 3.41830611e-01,\n",
        "        7.98922718e-01, 7.98846304e-01],\n",
        "       [2.08248302e-01, 4.43367690e-01, 7.15601265e-01, 4.10519779e-01,\n",
        "        1.91006958e-01, 9.67494309e-01, 6.50750339e-01, 8.65459859e-01,\n",
        "        2.52423584e-02, 2.66905814e-01],\n",
        "       [5.02071083e-01, 6.74486384e-02, 9.93033290e-01, 2.36462399e-01,\n",
        "        3.74292195e-01, 2.14011908e-01, 1.05445869e-01, 2.32479781e-01,\n",
        "        3.00610125e-01, 6.34442270e-01],\n",
        "       [2.81234771e-01, 3.62276763e-01, 5.94284385e-03, 3.65719140e-01,\n",
        "        5.33885956e-01, 1.62015840e-01, 5.97433090e-01, 2.93152481e-01,\n",
        "        6.32050514e-01, 2.61966046e-02],\n",
        "       [8.87593448e-01, 1.61186308e-02, 1.26958027e-01, 7.77162433e-01,\n",
        "        4.58952338e-02, 7.10998714e-01, 9.71046150e-01, 8.71682942e-01,\n",
        "        7.10161626e-01, 9.58509743e-01],\n",
        "       [4.29813325e-01, 8.72878909e-01, 3.55957657e-01, 9.29763675e-01,\n",
        "        1.48777649e-01, 9.40029025e-01, 8.32716227e-01, 8.46054852e-01,\n",
        "        1.23923011e-01, 5.96486926e-01],\n",
        "       [1.63924806e-02, 7.21184373e-01, 7.73751410e-03, 8.48222747e-02,\n",
        "        2.25498408e-01, 8.75124514e-01, 3.63576323e-01, 5.39959908e-01,\n",
        "        5.68103194e-01, 2.25463361e-01],\n",
        "       [5.72146773e-01, 6.60951793e-01, 2.98245400e-01, 4.18626845e-01,\n",
        "        4.53088939e-01, 9.32350636e-01, 5.87493777e-01, 9.48252380e-01,\n",
        "        5.56034744e-01, 5.00561416e-01],\n",
        "       [3.53221106e-03, 4.80889052e-01, 9.27455008e-01, 1.98365688e-01,\n",
        "        5.20911328e-02, 4.06778902e-01, 3.72396469e-01, 8.57153058e-01,\n",
        "        2.66111158e-02, 9.20149207e-01],\n",
        "       [6.80903018e-01, 9.04226005e-01, 6.07529044e-01, 8.11953306e-01,\n",
        "        3.35543871e-01, 3.49566221e-01, 3.89874220e-01, 7.54797101e-01,\n",
        "        3.69291186e-01, 2.42219806e-01],\n",
        "       [9.37668383e-01, 9.08011079e-01, 3.48797321e-01, 6.34638071e-01,\n",
        "        2.73842216e-01, 2.06115127e-01, 3.36339533e-01, 3.27099890e-01,\n",
        "        8.82276118e-01, 8.22303832e-01],\n",
        "       [7.09623218e-01, 9.59345222e-01, 4.22543347e-01, 2.45033041e-01,\n",
        "        1.17398441e-01, 3.01053345e-01, 1.45263731e-01, 9.21861008e-02,\n",
        "        6.02932215e-01, 3.64187449e-01],\n",
        "       [5.64570367e-01, 1.91335723e-01, 6.76905870e-01, 2.15505451e-01,\n",
        "        2.78023601e-01, 7.41760433e-01, 5.59737921e-01, 3.34836423e-01,\n",
        "        5.42988777e-01, 6.93984687e-01],\n",
        "       [9.12132144e-01, 5.80713212e-01, 2.32686386e-01, 7.46697605e-01,\n",
        "        7.77769029e-01, 2.00401321e-01, 8.20574224e-01, 4.64934856e-01,\n",
        "        7.79766679e-01, 2.37478226e-01],\n",
        "       [3.32580268e-01, 9.53697145e-01, 6.57815099e-01, 7.72877812e-01,\n",
        "        6.88374341e-01, 2.04304114e-01, 4.70688760e-01, 8.08963895e-01,\n",
        "        6.75035119e-01, 6.02788571e-03],\n",
        "       [8.74077454e-02, 3.46794724e-01, 9.44365561e-01, 4.91190493e-01,\n",
        "        2.70176262e-01, 3.60423714e-01, 2.10652635e-01, 4.21200067e-01,\n",
        "        2.18035445e-01, 8.45752478e-01],\n",
        "       [4.56270605e-01, 2.79802024e-01, 9.32891667e-01, 3.14351350e-01,\n",
        "        9.09714639e-01, 4.34180908e-02, 7.07115054e-01, 4.83889043e-01,\n",
        "        4.44221050e-01, 3.63233462e-02],\n",
        "       [4.06831913e-02, 3.32753628e-01, 9.47119534e-01, 6.17659986e-01,\n",
        "        3.68874848e-01, 6.11977041e-01, 2.06131533e-01, 1.65066436e-01,\n",
        "        3.61817271e-01, 8.63353372e-01],\n",
        "       [5.09401739e-01, 2.96901524e-01, 9.50251639e-01, 8.15966070e-01,\n",
        "        3.22973937e-01, 9.72098231e-01, 9.87351120e-01, 4.08660144e-01,\n",
        "        6.55923128e-01, 4.05653208e-01],\n",
        "       [2.57348120e-01, 8.26526731e-02, 2.63610333e-01, 2.71479845e-01,\n",
        "        3.98639083e-01, 1.84886038e-01, 9.53818381e-01, 1.02879882e-01,\n",
        "        6.25208557e-01, 4.41697389e-01],\n",
        "       [4.23518062e-01, 3.71991783e-01, 8.68314683e-01, 2.80476987e-01,\n",
        "        2.05761567e-02, 9.18097019e-01, 8.64480257e-01, 2.76901782e-01,\n",
        "        5.23487568e-01, 1.09088197e-01],\n",
        "       [9.34270695e-02, 8.37466121e-01, 4.10265714e-01, 6.61716521e-01,\n",
        "        9.43200588e-01, 2.45130599e-01, 1.31598311e-02, 2.41484065e-02,\n",
        "        7.09385693e-01, 9.24551904e-01],\n",
        "       [4.67330277e-01, 3.75109136e-01, 5.42860448e-01, 8.58916819e-01,\n",
        "        6.52153850e-01, 2.32979894e-01, 7.74580181e-01, 1.34613499e-01,\n",
        "        1.65559977e-01, 6.12682283e-01],\n",
        "       [2.38783404e-01, 7.04778552e-01, 3.49518538e-01, 2.77423948e-01,\n",
        "        9.98918414e-01, 4.06161249e-02, 6.45822525e-01, 3.86995859e-02,\n",
        "        7.60210276e-01, 2.30089962e-01],\n",
        "       [8.98318663e-02, 6.48449719e-01, 7.32601225e-01, 6.78095341e-01,\n",
        "        5.19009456e-02, 2.94306934e-01, 4.51088339e-01, 2.87103295e-01,\n",
        "        8.10513437e-01, 1.31115109e-01],\n",
        "       [6.12179339e-01, 9.88214970e-01, 9.02556539e-01, 2.22157061e-01,\n",
        "        8.18876142e-05, 9.80597317e-01, 8.82712960e-01, 9.19472456e-01,\n",
        "        4.15503561e-01, 7.44615436e-01],\n",
        "       [2.12831497e-01, 3.92304063e-01, 8.51548076e-01, 1.27612218e-01,\n",
        "        8.93865347e-01, 4.96507972e-01, 4.26095665e-01, 3.05646390e-01,\n",
        "        9.16848779e-01, 5.17623484e-01],\n",
        "       [8.04026365e-01, 8.57651770e-01, 9.22382355e-01, 3.03380728e-01,\n",
        "        3.39810848e-01, 5.95073879e-01, 4.41324145e-01, 9.32842553e-01,\n",
        "        3.97564054e-01, 4.77778047e-01],\n",
        "       [6.17186069e-01, 4.04739499e-01, 9.92478430e-01, 9.88512859e-02,\n",
        "        2.20603317e-01, 3.22655141e-01, 1.47722840e-01, 2.84219235e-01,\n",
        "        7.79245317e-01, 5.22891998e-01],\n",
        "       [3.39536369e-02, 9.82622564e-01, 6.16006494e-01, 5.89394793e-02,\n",
        "        6.61168754e-01, 3.78369361e-01, 1.35673299e-01, 5.63664615e-01,\n",
        "        7.27079928e-01, 6.71126604e-01],\n",
        "       [2.47513160e-01, 5.24866223e-01, 5.37663460e-01, 7.16803372e-01,\n",
        "        3.59867334e-01, 7.97732592e-01, 6.27921820e-01, 3.83316055e-02,\n",
        "        5.46479046e-01, 8.61912072e-01],\n",
        "       [5.67574143e-01, 1.75828263e-01, 5.10376394e-01, 7.56945848e-01,\n",
        "        1.10105194e-01, 8.17099094e-01, 1.67481646e-01, 5.34076512e-01,\n",
        "        3.85743469e-01, 2.48623773e-01],\n",
        "       [6.47432506e-01, 3.73921096e-02, 7.60045826e-01, 5.26940644e-01,\n",
        "        8.75771224e-01, 5.20718336e-01, 3.50331701e-02, 1.43600971e-01,\n",
        "        7.95604587e-01, 4.91976053e-01],\n",
        "       [4.41879272e-01, 3.18434775e-01, 2.84549206e-01, 9.65886295e-01,\n",
        "        4.32969332e-01, 8.84003043e-01, 6.48163140e-01, 8.58427644e-01,\n",
        "        8.52449536e-01, 9.56312001e-01],\n",
        "       [6.97942257e-01, 8.05396914e-01, 7.33127892e-01, 6.05226815e-01,\n",
        "        7.17354119e-01, 7.15750396e-01, 4.09077927e-02, 5.16110837e-01,\n",
        "        7.92651355e-01, 2.42962182e-01],\n",
        "       [4.65147972e-01, 4.34985697e-01, 4.02787179e-01, 1.21839531e-01,\n",
        "        5.25711536e-01, 4.46248353e-01, 6.63392782e-01, 5.49413085e-01,\n",
        "        2.75429301e-02, 3.19179893e-02],\n",
        "       [7.01359808e-01, 7.07581103e-01, 9.59939122e-01, 8.76704693e-01,\n",
        "        4.68059659e-01, 6.25906527e-01, 4.57181722e-01, 2.22946241e-01,\n",
        "        3.76677006e-01, 1.03884235e-01],\n",
        "       [6.66527092e-01, 1.92030147e-01, 4.75467801e-01, 9.67436612e-01,\n",
        "        3.16689312e-02, 1.51729956e-01, 2.98579186e-01, 9.41806972e-01,\n",
        "        9.08841789e-01, 1.62000835e-01],\n",
        "       [9.81117785e-01, 7.50747502e-01, 5.39977074e-01, 9.31702912e-01,\n",
        "        8.80607128e-01, 3.91316503e-01, 6.56343222e-01, 6.47385120e-01,\n",
        "        3.26968193e-01, 1.79390177e-01],\n",
        "       [4.66809869e-01, 2.63281047e-01, 3.55065137e-01, 9.54143941e-01,\n",
        "        4.61137861e-01, 6.84891462e-01, 3.36229891e-01, 9.95861053e-01,\n",
        "        6.58767581e-01, 1.96009472e-01],\n",
        "       [9.81839970e-02, 9.43180561e-01, 9.44777846e-01, 6.21328354e-01,\n",
        "        1.69914998e-02, 2.25534886e-01, 8.01276803e-01, 8.75459850e-01,\n",
        "        4.53989804e-01, 3.65520626e-01],\n",
        "       [2.74224997e-01, 1.16970517e-01, 1.15744539e-01, 9.52602684e-01,\n",
        "        8.08626115e-01, 1.64779365e-01, 2.07050055e-01, 6.55551553e-01,\n",
        "        7.64664233e-01, 8.10314834e-01],\n",
        "       [1.63337693e-01, 9.84128296e-01, 2.27802068e-01, 5.89415431e-01,\n",
        "        5.87615728e-01, 9.67361867e-01, 6.57667458e-01, 5.84904253e-01,\n",
        "        5.18772602e-01, 7.64657557e-01],\n",
        "       [1.06055260e-01, 2.09190114e-03, 9.52488840e-01, 4.98657674e-01,\n",
        "        3.28335375e-01, 3.68053257e-01, 8.03843319e-01, 3.82370204e-01,\n",
        "        7.70169199e-01, 4.40461993e-01],\n",
        "       [8.44077468e-01, 7.62040615e-02, 4.81128335e-01, 4.66849715e-01,\n",
        "        2.64327973e-01, 9.43614721e-01, 9.05028462e-01, 4.43596303e-01,\n",
        "        9.71596092e-02, 2.06783146e-01],\n",
        "       [2.71491826e-01, 4.84219760e-01, 3.38377118e-01, 7.74136066e-01,\n",
        "        4.76026595e-01, 8.70370507e-01, 9.95781779e-01, 2.19835952e-01,\n",
        "        6.11671388e-01, 8.47502291e-01],\n",
        "       [9.45236623e-01, 2.90086418e-01, 7.27042735e-01, 1.50161488e-02,\n",
        "        8.79142463e-01, 6.39385507e-02, 7.33395398e-01, 9.94610369e-01,\n",
        "        5.01189768e-01, 2.09333986e-01],\n",
        "       [5.94643593e-01, 6.24149978e-01, 6.68072760e-01, 1.72611743e-01,\n",
        "        8.98712695e-01, 6.20991349e-01, 4.35687043e-02, 6.84041083e-01,\n",
        "        1.96084052e-01, 2.73407809e-02],\n",
        "       [5.50953269e-01, 8.13313663e-01, 8.59941125e-01, 1.03520922e-01,\n",
        "        6.63042784e-01, 7.10075200e-01, 2.94516981e-01, 9.71364021e-01,\n",
        "        2.78687477e-01, 6.99821860e-02],\n",
        "       [5.19280374e-01, 6.94314897e-01, 2.44659781e-01, 3.38582188e-01,\n",
        "        5.63627958e-01, 8.86678159e-01, 7.47325897e-01, 2.09591955e-01,\n",
        "        2.51777083e-01, 5.23880661e-01],\n",
        "       [7.68958688e-01, 6.18761778e-01, 5.01324296e-01, 5.97125351e-01,\n",
        "        7.56060004e-01, 5.37079811e-01, 8.97752762e-01, 9.47067499e-01,\n",
        "        9.15354490e-01, 7.54518330e-01],\n",
        "       [2.46321008e-01, 3.85271460e-01, 2.79999942e-01, 6.57660246e-01,\n",
        "        3.24221611e-01, 7.54391611e-01, 1.13509081e-01, 7.75364757e-01,\n",
        "        5.85901976e-01, 8.35388660e-01],\n",
        "       [4.30875659e-01, 6.24964476e-01, 5.54412127e-01, 9.75671291e-01,\n",
        "        7.55474389e-01, 5.44813275e-01, 1.74032092e-01, 9.04114246e-01,\n",
        "        2.05837786e-01, 6.50043249e-01],\n",
        "       [9.36471879e-01, 2.23579630e-01, 2.25923538e-01, 8.51818919e-01,\n",
        "        8.27655017e-01, 3.51703346e-01, 2.65096277e-01, 1.27388477e-01,\n",
        "        9.87936080e-01, 8.35343122e-01],\n",
        "       [8.99391592e-01, 5.13679326e-01, 1.14384830e-01, 5.25803380e-02,\n",
        "        3.30582112e-01, 9.20330405e-01, 9.47581828e-01, 8.41163874e-01,\n",
        "        1.58679143e-01, 4.19923156e-01],\n",
        "       [2.46242926e-01, 2.05349773e-01, 6.84825838e-01, 4.86111671e-01,\n",
        "        3.24909657e-01, 1.00214459e-01, 5.44763386e-01, 3.47025156e-01,\n",
        "        3.91095817e-01, 3.10508728e-01],\n",
        "       [3.87195200e-01, 5.55859566e-01, 1.41438060e-02, 8.47647011e-01,\n",
        "        9.21919882e-01, 5.50529718e-01, 2.68021107e-01, 9.90239024e-01,\n",
        "        3.83194029e-01, 6.93655372e-01],\n",
        "       [6.89952552e-01, 4.34309065e-01, 1.99158162e-01, 9.66579378e-01,\n",
        "        6.36908561e-02, 4.85149384e-01, 2.20730707e-01, 2.93974131e-01,\n",
        "        8.28527331e-01, 3.67265552e-01],\n",
        "       [8.33482668e-02, 1.96309000e-01, 8.60373437e-01, 9.77028847e-01,\n",
        "        2.67982155e-01, 6.75408959e-01, 8.11989978e-02, 7.23465621e-01,\n",
        "        4.16436613e-01, 9.18159902e-01],\n",
        "       [3.11536163e-01, 9.41466987e-01, 5.03247440e-01, 3.48892927e-01,\n",
        "        6.47019625e-01, 2.49746203e-01, 2.29763597e-01, 1.96346447e-01,\n",
        "        9.59899545e-01, 4.92913723e-01],\n",
        "       [7.51614988e-01, 4.73991871e-01, 5.87540150e-01, 5.84138989e-01,\n",
        "        9.79886293e-01, 6.68433130e-01, 2.39769474e-01, 1.51976589e-02,\n",
        "        2.18682140e-01, 4.55519646e-01],\n",
        "       [3.93420339e-01, 8.12326252e-01, 7.85556734e-01, 8.90959650e-02,\n",
        "        9.52010751e-01, 5.27456701e-01, 5.96403956e-01, 4.05056775e-01,\n",
        "        6.49500966e-01, 8.71326327e-01],\n",
        "       [6.73935950e-01, 9.70098555e-01, 7.01122224e-01, 8.21720719e-01,\n",
        "        4.50395830e-02, 6.72698498e-01, 6.54752672e-01, 1.01746053e-01,\n",
        "        8.42387497e-01, 6.14172399e-01],\n",
        "       [9.83280912e-02, 5.94467103e-01, 4.78415847e-01, 2.33293563e-01,\n",
        "        1.97560899e-02, 3.65567267e-01, 6.19851053e-01, 3.29279125e-01,\n",
        "        3.07254642e-01, 7.51121223e-01],\n",
        "       [7.58624673e-01, 7.18765855e-01, 1.01181954e-01, 5.16165972e-01,\n",
        "        5.57798684e-01, 7.44804502e-01, 9.03177738e-01, 3.69038880e-01,\n",
        "        4.28663462e-01, 7.32767463e-01],\n",
        "       [6.62636399e-01, 5.57869911e-01, 3.50139618e-01, 1.95352346e-01,\n",
        "        1.83807373e-01, 8.15832913e-02, 8.12008530e-02, 8.45798194e-01,\n",
        "        3.83672744e-01, 6.07396215e-02],\n",
        "       [8.96425664e-01, 2.23270476e-01, 2.68124431e-01, 1.94497839e-01,\n",
        "        9.67501044e-01, 1.12540089e-01, 7.22163260e-01, 9.32088733e-01,\n",
        "        6.68001294e-01, 8.58726621e-01],\n",
        "       [2.42447108e-01, 6.73927963e-01, 7.00871348e-01, 4.58332509e-01,\n",
        "        8.70545626e-01, 6.94386125e-01, 8.94877791e-01, 7.53204346e-01,\n",
        "        5.20290434e-01, 4.98688221e-01],\n",
        "       [4.53727633e-01, 2.16468628e-02, 5.35141408e-01, 4.22973245e-01,\n",
        "        1.57533601e-01, 1.19069695e-01, 4.49351877e-01, 3.99130546e-02,\n",
        "        9.86579895e-01, 3.78120929e-01],\n",
        "       [3.82109195e-01, 5.11263013e-02, 4.26672339e-01, 1.57454368e-02,\n",
        "        3.00936326e-02, 3.39099228e-01, 8.20968926e-01, 4.58821088e-01,\n",
        "        1.48405796e-02, 1.63220033e-01],\n",
        "       [7.39922702e-01, 7.38293707e-01, 7.54522920e-01, 3.51669371e-01,\n",
        "        3.52276951e-01, 8.02075684e-01, 3.98137897e-01, 7.27191031e-01,\n",
        "        5.81122994e-01, 3.64341676e-01],\n",
        "       [8.00065175e-02, 1.16125375e-01, 8.89558733e-01, 4.52340513e-01,\n",
        "        9.94004548e-01, 3.63896936e-01, 2.49954298e-01, 3.50539327e-01,\n",
        "        3.43086094e-01, 6.37356758e-01],\n",
        "       [1.27375638e-02, 7.63268650e-01, 4.16414618e-01, 4.32239205e-01,\n",
        "        4.81115013e-01, 4.49212462e-01, 4.97470886e-01, 3.45904320e-01,\n",
        "        4.53346133e-01, 4.04651344e-01],\n",
        "       [5.18242717e-01, 6.23269081e-01, 2.41040602e-01, 5.08437157e-01,\n",
        "        5.94621897e-01, 1.69483144e-02, 5.20493746e-01, 2.39293247e-01,\n",
        "        4.04538542e-01, 8.26530159e-01],\n",
        "       [3.26235592e-01, 4.83216912e-01, 2.47411542e-02, 3.08750868e-01,\n",
        "        6.39721096e-01, 3.15161765e-01, 2.05797508e-01, 2.90655673e-01,\n",
        "        9.54378307e-01, 8.68018195e-02],\n",
        "       [4.63357776e-01, 5.83869033e-02, 5.38658261e-01, 1.46035731e-01,\n",
        "        6.34084821e-01, 2.64397472e-01, 6.90915406e-01, 3.47146064e-01,\n",
        "        4.16848855e-03, 2.94894695e-01]], dtype=tf.float32)"
      ],
      "metadata": {
        "id": "HDHewW3oragZ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the first dense layer\n",
        "dense1 = tf.keras.layers.Dense(7, activation='sigmoid')(borrower_features)\n",
        "\n",
        "# Define a dense layer with 3 output nodes\n",
        "dense2 = tf.keras.layers.Dense(3, activation='sigmoid')(dense1)\n",
        "\n",
        "# Define a dense layer with 1 output node\n",
        "predictions = tf.keras.layers.Dense(1, activation='sigmoid')(dense2)\n",
        "\n",
        "# Print the shapes of dense1, dense2, and predictions\n",
        "print('\\n shape of dense1: ', dense1.shape)\n",
        "print('\\n shape of dense2: ', dense2.shape)\n",
        "print('\\n shape of predictions: ', predictions.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqOmLWSZsVC8",
        "outputId": "b1b74f4c-ee6b-43a9-cf52-1a707b79509d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " shape of dense1:  (100, 7)\n",
            "\n",
            " shape of dense2:  (100, 3)\n",
            "\n",
            " shape of predictions:  (100, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Activation functions*:\n",
        "- sogmoid: binary classifications\n",
        "- relu\n",
        "- softmax: > 2 classes"
      ],
      "metadata": {
        "id": "LTB82MQDPsgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bill_amounts = tf.constant([[77479, 77057, 78102],\n",
        "       [  326,   326,   326],\n",
        "       [13686,  1992,   604],\n",
        "       [  944,  1819,  1133],\n",
        "       [    0,     0,     0],\n",
        "       [96491, 94043, 97522]], tf.float32)\n",
        "\n",
        "default = tf.constant([[0],\n",
        "       [0],\n",
        "       [0],\n",
        "       [0],\n",
        "       [1],\n",
        "       [0]])"
      ],
      "metadata": {
        "id": "_VQNcukfsWoV"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define first dense layer\n",
        "dense1 = tf.keras.layers.Dense(3, activation='relu')(bill_amounts)\n",
        "\n",
        "# Define second dense layer\n",
        "dense2 = tf.keras.layers.Dense(2, \"relu\")(dense1)\n",
        "\n",
        "# Define output layer\n",
        "outputs = tf.keras.layers.Dense(1, \"sigmoid\")(dense2)\n",
        "\n",
        "# Print error for first five examples\n",
        "error = default[:5] - outputs.numpy()[:5]\n",
        "print(error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5VnibJRVuXn",
        "outputId": "0566d3c2-a57c-4f80-e6a8-dc6d10d86723"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]], shape=(5, 1), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "errors change each time we run the code. This is because using an untrained model with randomly initialized parameters. Furthermore, the errors fall on the interval between -1 and 1 because default is a binary variable that takes on values of 0 and 1 and outputs is a probability between 0 and 1."
      ],
      "metadata": {
        "id": "ZVDlaAXuW_9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "borrower_features = tf.constant([[180201, 181443, 155045,   3100,  92101,   3200],\n",
        "       [ 12200,   8140,  10176,  15027,    639,    547],\n",
        "       [  1078,   5543,    500,    617,      0,      0],\n",
        "       [   291,    763,   2403,      0,      0,    291],\n",
        "       [ 86076,  87567,  78646,   3116,   2000,   2100],\n",
        "       [  7791,   5851,    430,   2041,    775,    580]], tf.float32)"
      ],
      "metadata": {
        "id": "dvvwz4icWuQ8"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.constant(borrower_features, tf.float32)\n",
        "\n",
        "# Define first dense layer\n",
        "dense1 = tf.keras.layers.Dense(10, activation='sigmoid')(inputs)\n",
        "\n",
        "# Define second dense layer\n",
        "dense2 = tf.keras.layers.Dense(8, activation=\"relu\")(dense1)\n",
        "\n",
        "# Define output layer\n",
        "outputs = tf.keras.layers.Dense(6,activation=\"softmax\")(dense2)\n",
        "\n",
        "# Print first five predictions\n",
        "print(outputs.numpy()[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pB2ElVB_XzTf",
        "outputId": "2bc5e6f8-8b42-4a2a-9ab3-b49a5352bc62"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.10479642 0.12526429 0.21481171 0.09495132 0.13659799 0.32357824]\n",
            " [0.11342227 0.10006487 0.2876262  0.11272124 0.23124652 0.15491891]\n",
            " [0.1422948  0.08794262 0.31339177 0.08250479 0.22534603 0.14852   ]\n",
            " [0.17716238 0.07112992 0.27059639 0.06877894 0.25634095 0.15599136]\n",
            " [0.10479642 0.12526429 0.21481171 0.09495132 0.13659799 0.32357824]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.reduce_sum(outputs, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dZu6HIRXf_z",
        "outputId": "2af27ae6-6f7e-47e1-b086-106585ae91de"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6,), dtype=float32, numpy=\n",
              "array([0.99999994, 1.        , 1.        , 0.99999994, 0.99999994,\n",
              "       0.99999994], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "each row of outputs sums to one. This is because a row contains the predicted class probabilities for one example. As with the previous exercise, our predictions are not yet informative, since we are using an untrained model with randomly initialized parameters. This is why the model tends to assign similar probabilities to each class."
      ],
      "metadata": {
        "id": "lq2M6BIEY1Kq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Optimizers*:\n",
        "- Stochasticgradientdescent (SGD): simple and easy to interpret\n",
        "- Rootmeansquared (RMS): allows for momentum to both buil and decay (different learning rates for different features)\n",
        "- Adaptive moment (Adam): performs well with default parameter values\n",
        "\n",
        "*Learning rate*:\n",
        "- with higher learning rate the ball will more faster and will skip some plateau but may also skip global minimum"
      ],
      "metadata": {
        "id": "0QTlbdufRLMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def loss_function(x):\n",
        "\treturn 4.0*math.cos(x-1)+tf.divide(math.cos(2.0*3.141592653589793*x),x)"
      ],
      "metadata": {
        "id": "VGLhMLxCYv7M"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize x_1 and x_2 with names\n",
        "x_1 = tf.Variable(6.0, tf.float32, name='x_1')\n",
        "x_2 = tf.Variable(0.3, tf.float32, name='x_2')\n",
        "\n",
        "# Define the optimization operation\n",
        "opt = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "\n",
        "# Build the optimizer with the variables\n",
        "variables = [x_1, x_2]\n",
        "opt.build(variables)\n",
        "\n",
        "for j in range(100):\n",
        "    # Compute gradients using the loss function and x_1\n",
        "    gradients_x_1 = opt.minimize(lambda: loss_function(x_1), [x_1])\n",
        "    # Compute gradients using the loss function and x_2\n",
        "    gradients_x_2 = opt.minimize(lambda: loss_function(x_2), [x_2])\n",
        "\n",
        "# Print x_1 and x_2 as numpy arrays\n",
        "print(x_1.numpy(), x_2.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzH-USCxa-rv",
        "outputId": "d931d6f5-9103-40ef-bb21-eb230fc137cd"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.027515 0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that we used the same optimizer and loss function, but two different initial values. When we started at 6.0 with x_1, we found the global minimum at 6.02. When we started at 0.3, we stopped around 0.25 with x_2"
      ],
      "metadata": {
        "id": "JEmUsG9rcyPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize x_1 and x_2\n",
        "x_1 = tf.Variable(0.05,tf.float32)\n",
        "x_2 = tf.Variable(0.05,tf.float32)\n",
        "\n",
        "# Define the optimization operation for opt_1 and opt_2\n",
        "opt_1 = tf.keras.optimizers.RMSprop(learning_rate=0.01, momentum=0.99)\n",
        "opt_2 = tf.keras.optimizers.RMSprop(learning_rate=0.01, momentum=0.00)\n",
        "\n",
        "for j in range(100):\n",
        "\topt_1.minimize(lambda: loss_function(x_1), var_list=[x_1])\n",
        "    # Define the minimization operation for opt_2\n",
        "\topt_2.minimize(lambda: loss_function(x_2), var_list=[x_2])\n",
        "\n",
        "# Print x_1 and x_2 as numpy arrays\n",
        "print(x_1.numpy(), x_2.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLiZsJwfbLr0",
        "outputId": "d5503899-2daa-4277-f8b9-5b65e7a9a76a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.744512 0.24999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Momentum helps to break through local minimum. Notice that opt_1 built momentum, bringing x_1 closer to the global minimum. To the contrary, opt_2, which had a momentum parameter of 0.0, got stuck in the local minimum."
      ],
      "metadata": {
        "id": "7qCLpFuUd582"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dropout** drops weights\n",
        "\n",
        "**A good initialization can reduce the amount of time needed to find the global minimum.**"
      ],
      "metadata": {
        "id": "9fdTRBZ5U6x4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Hight-level APIs**"
      ],
      "metadata": {
        "id": "UH_TzmfoidPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a tf.Keras sequential model\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "# Define the first dense layer\n",
        "model.add(tf.keras.layers.Dense(16, activation='relu', input_shape=(784,)))\n",
        "\n",
        "# Define the second dense layer\n",
        "model.add(tf.keras.layers.Dense(8, activation='relu', input_shape=(784,)))\n",
        "\n",
        "# Define the output layer\n",
        "model.add(tf.keras.layers.Dense(4, activation='softmax', input_shape=(784,)))\n",
        "\n",
        "# Print the model architecture\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwcbb6wYifYO",
        "outputId": "83843737-7b7e-4999-935f-2fe04f527fcb"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 16)                12560     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 4)                 36        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12732 (49.73 KB)\n",
            "Trainable params: 12732 (49.73 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that we've defined a model, but we haven't compiled it. The compilation step in keras allows us to set the optimizer, loss function, and other useful training parameters in a single line of code."
      ],
      "metadata": {
        "id": "RVdv--COi8z9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the first dense layer\n",
        "model.add(tf.keras.layers.Dense(16, activation=\"sigmoid\", input_shape=(784,)))\n",
        "\n",
        "# Apply dropout to the first layer's output\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "# Define the output layer\n",
        "model.add(tf.keras.layers.Dense(4, activation=\"softmax\"))\n",
        "\n",
        "# Compile the model\n",
        "model.compile('adam', loss='categorical_crossentropy')\n",
        "\n",
        "# Print a model summary\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iNsw4NpitlN",
        "outputId": "a60c4e7c-0788-4181-a47d-c310fb92143f"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 16)                12560     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 4)                 36        \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 16)                80        \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12880 (50.31 KB)\n",
            "Trainable params: 12880 (50.31 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    }
  ]
}